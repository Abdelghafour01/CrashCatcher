{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash Catcher: DashCam Accident Detector  </br>\n",
    "### Determining whether dashboard camera video contains an accident</br></br>\n",
    "I use a hierchical recurrent neural network implementation, trained on a set of videos with and without accidents, to determine whether a new video contains an accident or not.</br></br></br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## we want any plots to show up in the notebook\n",
    "%matplotlib inline\n",
    "## has the usual packages I use\n",
    "%run startup\n",
    "import numpy\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import timeit\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from skimage import transform\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split   ### import sklearn tool\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "rcdefaults()  ### set the defaults\n",
    "matplotlib.rc('font',family='Bitstream Vera Serif')   ### I like my plots to look a certain way :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, write a function to load in a video (.mp4 format, 720 by 1280 in size) from file. Each frame of the video will be converted to an image that can be processed. \n",
    "\n",
    "In order to make the process (marginally) less memory-intensive, we downscale the image to a size of 144 pixels by 256 pixels. In addition, because the images are originally in RGB color, we convert to gray-scale. This also reduces the amount of memory, and while some useful information may be lost, the color variations from scene to scene (or dashcam to dashcam) are less important. Further, losing the color dimension turns a 5-D problem into a 4-D problem -- a bit more tractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### here is the function to load in a video from file for analysis\n",
    "\n",
    "def load_set(videofile):\n",
    "    '''The input is the path to the video file - the training videos are 99 frames long and have resolution of 720x1248\n",
    "       This will be used for each video, individially, to turn the video into a sequence/stack of frames as arrays\n",
    "       The shape returned (img) will be 99 (frames per video), 144 (pixels per column), 256 (pixels per row))\n",
    "    '''\n",
    "    ### below, the video is loaded in using VideoCapture function\n",
    "    vidcap = cv2.VideoCapture(videofile)\n",
    "    ### now, read in the first frame\n",
    "    success,image = vidcap.read()\n",
    "    count = 0       ### start a counter at zero\n",
    "    success = True  ### start \"sucess\" flag at True\n",
    "\n",
    "    img = []        ### create an array to save each image as an array as its loaded \n",
    "    while success:  ### e.g.: while success == True\n",
    "        success, image = vidcap.read()  ### if success is still true, attempt to read in next frame from vidcap video import\n",
    "        ### read in only if there is an image \n",
    "        ### (this won't be true at the end of the video, but we don't want to save an empty image)\n",
    "        if image!=None:\n",
    "            image = skimage.color.rgb2gray(image)   ### convert to grayscale\n",
    "            image = skimage.transform.downscale_local_mean(image, (5,5))   ### downsample the image to be a bit more usable\n",
    "            #print shape(image)   ### old print check\n",
    "            img.append(image)     ### save processed image to video stack\n",
    "        count += 1    ### increase count, and repeat\n",
    "    \n",
    "    return img ## return stack of processed, time-dependent images from video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the training data and randomly select and split the training and validation sets (some data is also set aside/not included for testing later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_filepath = '/pathway/to/videos' #### the filepath for the training video set\n",
    "neg_all = glob.glob(img_filepath + 'negative/*.mp4')               #### negative examples - ACCV\n",
    "pos_2 = glob.glob(img_filepath + 'positive/*.mp4')                 #### positive examples - ACCV\n",
    "pos_1 = glob.glob(img_filepath + '../YTpickles/*.pkl')             #### positive examples - youtube\n",
    "pos_all = concatenate((pos_1, pos_2))\n",
    "\n",
    "all_files = concatenate((pos_all, neg_all))\n",
    "print len(neg_all), len(pos_all)                                   #### print check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_matrix(values):\n",
    "    '''transforms labels for videos to one-hot encoding/dummy variables'''\n",
    "    n_values = numpy.max(values) + 1    ### take max value (that would be 1, because it is a binary classification), \n",
    "                                        ### and create n+1 (that would be two) sized matrix\n",
    "    return numpy.eye(n_values)[values]  ### return matrix with results coded - 1 in first column for no-accident, 1 in second for accident\n",
    "\n",
    "labels = numpy.concatenate(([1]*len(pos_all), [0]*len(neg_all[0:len(pos_all)])))  ### create the labels for the videos\n",
    "labels = label_matrix(labels)           ### make the labels into a matrix for the HRNN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data from each video and save to (massive) data array -- should be of shape (L, 99, 144, 256), where L is the number of files that are going to be used. We use a function to load in the data differently depending on whether it is pickled (from youtube) or part of the ACCV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(rand):\n",
    "    seq1 = numpy.zeros((len(rand), 99, 144, 256))   ### create an empty array to take in the data\n",
    "    for i,fi in enumerate(rand):                    ### for each file...\n",
    "        print (i, fi)                               ### as we go through, print out each one\n",
    "        if fi[-4:] == '.mp4':\n",
    "            t = load_set(fi)                        ### load in the video file using previously defined function if .mp4 file\n",
    "        elif fi[-4:]=='.pkl':\n",
    "            t = pickle.load(open(fi, 'rb'))         ### otherwise, if it's pickled data, load the pickle\n",
    "        if shape(t)==(99,144,256):                  ### double check to make sure the shape is correct, and accept\n",
    "            seq1[i] = t                             ### save image stack to array\n",
    "        else:# TypeError:\n",
    "            'Image has shape ', shape(t), 'but needs to be shape', shape(seq1[0]) ### if exception is raised, explain\n",
    "            pass                                    ### continue loading data\n",
    "    print (shape(seq1))\n",
    "    return seq1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then split (with the labels created above) into training and validation sets, with 60% of the total set as training and 20% as validation (the remaining 20% of data is left as a holdout test set).\n",
    "\n",
    "The split fractions may look a little odd, but they are essentially ensuring that the validation and test sets are the same size (an overall 60-20-20 for training-validation-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### split data into training and validation (sets and shuffle)\n",
    "x_train, x_t1, y_train, y_t1 = train_test_split(all_files, labels, test_size=0.40, random_state=0)  ### split\n",
    "x_train = array(x_train); y_train = array(y_train)                          ### need to be arrays\n",
    "\n",
    "x_testA = array(x_t1[len(x_t1)/2:]); y_testA = array(y_t1[len(y_t1)/2:])    #### test set\n",
    "\n",
    "### valid set for model\n",
    "x_testB = array(x_t1[:len(x_t1)/2]); y_testB = array(y_t1[:len(y_t1)/2])    ### need to be arrays\n",
    "x_test = make_dataset(x_testB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below, a test was run to check whether there is signal above the noise -- fake data was generated from random numbers to show that the real data performed better than data/patterns picked up from random data. \n",
    "\n",
    "Thankfully, the model could barely reach 50% accuracy when run with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### populate data as random numbers as a sanity check\n",
    "#seq3 = zeros((60,99,144,256))\n",
    "#for j in range(60):   ### for each file...\n",
    "#    [np.random.random((244,256)) for i in range(99)]    ### save image stack to array\n",
    "#print (shape(seq3))              ### print check\n",
    "\n",
    "#x_train2, x_test2, y_train2, y_test2 = train_test_split(seq3, labels, test_size=0.2, random_state=0)  ### split\n",
    "#x_train2 = array(x_train2); y_train2 = array(y_train2)     ### need to be arrays\n",
    "#x_test2 = array(x_test2); y_test2 = array(y_test2)         ### need to be arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below, the HRNN is set up to run on the train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### the code is largely appropriated from the following resource\n",
    "### https://github.com/fchollet/keras/blob/master/examples/mnist_hierarchical_rnn.py\n",
    "\n",
    "\"\"\"HRNNs can learn across multiple levels of temporal hiearchy over a complex sequence.\n",
    "Usually, the first recurrent layer of an HRNN encodes a time-dependent video (e.g. set of images)\n",
    "into a vector. The second recurrent layer then encodes those vectors (encoded by the first layer) into a second layer.\n",
    "# References\n",
    "    - [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://arxiv.org/abs/1506.01057)\n",
    "    - [Hierarchical recurrent neural network for skeleton based action recognition](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298714)\n",
    "The first LSTM layer first encodes every column of pixels of shape (240, 1) to a column vector of shape (128,).\n",
    "The second LSTM layer encodes then these 240 column vectors of shape (240, 128) to a image vector representing the whole image. \n",
    "A final Dense layer is added for prediction.\n",
    "\"\"\"\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "\n",
    "### set hyper-parameters\n",
    "batch_size = 15\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "### number of hidden layers in each NN\n",
    "row_hidden = 128\n",
    "col_hidden = 128\n",
    "\n",
    "### print basic info\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "### get shape of rows/columns for each image\n",
    "frame, row, col = (99, 144, 256)\n",
    "\n",
    "### 4D input - for each 3-D sequence (of 2-D image) in each video (4th)\n",
    "x = Input(shape=(frame, row, col))\n",
    "\n",
    "encoded_rows = TimeDistributed(LSTM(row_hidden))(x)  ### encodes row of pixels using TimeDistributed Wrapper\n",
    "encoded_columns = LSTM(col_hidden)(encoded_rows)     ### encodes columns of encoded rows using previous layer\n",
    "\n",
    "### set up prediction and compile the model\n",
    "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='binary_crossentropy',    ### loss choice for two-category classification\n",
    "              optimizer='NAdam',             ### NAdam optimization\n",
    "              metrics=['accuracy'])          ### grade on accuracy during each epoch/pass\n",
    "\n",
    "### create a filepath to save best results as we go - http://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "### because who wants to train this crazy stuff more than once??!\n",
    "i=0; filepath='HRNN_pretrained_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "### now we actually train - because of my laptop memory issues, this means the training data cannot\n",
    "### be loaded into memory all at once because python will crash. To get around this issue, we load in \n",
    "### the whole dataset and loop through in batches of 15. \n",
    "### However, each time we pass through the entire dataset, the order of the data needs to be randomized.\n",
    "### So, we shuffle the list of files during each epoch, then split into batches of 15 videos\n",
    "numpy.random.seed(18247)  ### set a random seed for repeatability\n",
    "\n",
    "for i in range(0, 30):               ### number of epochs\n",
    "    c = list(zip(x_train, y_train))  ### bind the features and labels together\n",
    "    random.shuffle(c)                ### shuffle the list\n",
    "    x_shuff, y_shuff = zip(*c)       ### unzip list into shuffled features and labels\n",
    "    x_shuff = array(x_shuff); y_shuff=array(y_shuff) ### back into arrays\n",
    "    \n",
    "    x_batch = [x_shuff[i:i + batch_size] for i in range(0, len(x_shuff), batch_size)] ### make features into batches of 15\n",
    "    y_batch = [y_shuff[i:i + batch_size] for i in range(0, len(x_shuff), batch_size)] ### make labels into batches of 15\n",
    "\n",
    "    for j,xb in enumerate(x_batch):  ### for each batch in the shuffled list for this epoch\n",
    "        xx = make_dataset(xb)        ### load the feature data into arrays\n",
    "        yy = y_batch[j]              ### set the labels for the batch\n",
    "        \n",
    "        model.fit(xx, yy,                            ### fit training data\n",
    "                  batch_size=len(xx),                ### reiterate batch size - in this case we already set up the batches\n",
    "                  epochs=1,                          ### number of times to run through each batch\n",
    "                  validation_data=(x_test, y_test),  ### validation set from up earlier in notebook\n",
    "                  callbacks=callbacks_list)          ### save if better than previous!\n",
    "\n",
    "# evaluate\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)    ### score model\n",
    "print('Test loss:', scores[0])                        ### test loss\n",
    "print('Test accuracy:', scores[1])                    ### test accuracy (ROC later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the results - ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### first, load and compile the saved model to make predictions\n",
    "model.load_weights(\"HRNN_pretrained_model.hdf5\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "\n",
    "### make the holdout test dataset for prediction and comparison\n",
    "x_holdout = make_dataset(x_testA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot([0,1],[0,1],'k:',alpha=0.5)                       ### plot the \"by chance\" line - the goal is to achieve better than random accuracy\n",
    "ys = [y_train, y_testB, y_testA]                       ### set up labels to be iterated through\n",
    "labs = ['Train', 'Valid', 'Test']                      ### set up tags to be iterated through\n",
    "col = ['#4881ea', 'darkgreen', 'maroon']               ### set up colors to be iterated through\n",
    "preds = []                                             ### set up prediction as empty array to populate\n",
    "for i,xset in enumerate([x_train, x_testB, x_testA]):  ### iterate through each set of data\n",
    "    if i==0:\n",
    "        new_pred = []                                  ### for first dataset, need to iterate through each\n",
    "        for k in xset:                                 ### to save memory (because we can't load the whole\n",
    "            d = make_dataset([k])                      ### thing at once)\n",
    "            new_pred.append(model.predict(d))          ### predictions with loaded model for each in training set\n",
    "        new_pred = array(new_pred).reshape((len(new_pred),2))\n",
    "    else:\n",
    "        d = make_dataset(xset)                         ### can load all of valid/test datasets at once in memory\n",
    "        new_pred = model.predict(d)                    ### predictions with loaded model for each valid/test dataset\n",
    "    preds.append(new_pred)\n",
    "    fpr, tpr, threshs = sklearn.metrics.roc_curve(ys[i][:,1], new_pred[:,1]) ### get the false pos rate and true pos rate\n",
    "    plot(fpr, tpr, '-', color=col[i], alpha=0.7, lw=1.5, label=labs[i])      ### plot the ROC curve with false pos rate and true pos rate\n",
    "    \n",
    "    print labs[i]\n",
    "    print sklearn.metrics.auc(fpr, tpr)                ### print area under curve for each set\n",
    "    print sklearn.metrics.accuracy_score(ys[i][:,1], [round(j) for j in new_pred[:,1]])   ### print accuracy for each set\n",
    "    print sklearn.metrics.confusion_matrix(ys[i][:,1], [round(j) for j in new_pred[:,1]]) ### print confusion matrix for each\n",
    "    \n",
    "xlabel('False Positive Rate'); ylabel('True Positive Rate')\n",
    "plt.legend(fancybox=True, loc=4, prop={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine probability range of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot([0,1],[0,1],'k:',alpha=0.5)                  ### plot the \"by chance\" line - trying so hard to be better than this...\n",
    "for i,p in enumerate(preds):                      ### for each of the calculated predictions, make a histogram\n",
    "    hist(p[:,1], bins = arange(0,1,0.05), histtype='stepfilled', color=col[i], alpha=0.7, label=labs[i]\n",
    "xlabel('False Positive Rate'); ylabel('True Positive Rate')\n",
    "plt.legend(fancybox=True, loc=2, prop={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
